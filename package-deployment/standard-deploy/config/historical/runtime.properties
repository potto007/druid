druid.service=historical

# Cache configs
druid.historical.cache.useCache=true
druid.historical.cache.populateCache=true

# Tier configs
#default
druid.server.priority=0

# While we could set this here, it is desirable to use some math based on the number of brokers in launch scripts (e.g. numThreads=numBrokers*druid.broker.http.numConnections)
# So push these settings into the launch scripts.
# From Hagen Rother:
# The sum of all druid.broker.http.numConnections must be smaller than each druid.server.http.numThreads (i.e. check each historical and realtime)
# (If the number of threads is larger, one can end up with a deadlock situation distributing the queries to the realtime/historical query nodes.)
#druid.server.http.numThreads=100

druid.server.maxSize=5497559962838

#default
druid.processing.buffer.sizeBytes=1073741824
druid.processing.numThreads=16

druid.segmentCache.locations=[{"path": "/druid/local/historical/indexCache", "maxSize"\: 5497559962838}]

com.metamx.query.groupBy.maxResults=5000000
druid.query.groupBy.maxResults=5000000

druid.monitoring.monitors=["io.druid.server.metrics.ServerMonitor", "com.metamx.metrics.SysMonitor","com.metamx.metrics.JvmMonitor"]